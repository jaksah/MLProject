This section describes the method of investigating the different classifiers, how the data is processed and the settings used when classifying. Figure \ref{fig:flowchart} illustrates the outline of the process.
\begin{figure}[H]
\begin{center}
\input{sections/flowchart.tex}
\caption{The process of making the vocabulary and a feature vector. The vocabulary reads the whole training set and the feature vector reads one article in the test set.}
\label{fig:flowchart}
\end{center}
\end{figure}

\subsection{Data Retrieval}
A crawler was implemented to extract articles from BBC's RSS feed\footnote{\url{http://www.bbc.com/news/10628494}}. The crawler extracts the content of each article from eight different topics, namely
\begin{itemize}[noitemsep,nolistsep]
\small
	\item Business
	\item Education
	\item Entertainment and Art
	\item Health
	\item Politics
	\item Science and Environment
	\item Sports
	\item Technology.
\end{itemize}
A total of 734 articles were extracted. As training set 2/3 of the articles were randomly selected and the remaining 1/3 were used as test set. Notable is that the distribution of topics is not uniform since the RSS feeds of the topics are not updated equally frequent. 
\subsection{Coding}
Python is chosen as programming language in order to extend our knowledge and experience of implementing different types of classifiers using the Scikit-learn machine learning library in Python and further understand how the data has to be prepared and presented to the classifiers.
\subsection{Preparation of Data}
To classify the articles as accurately and fast as possible, the data is prepared in such way that it contains as much information as possible in a format as dense as possible. To achieve this, the articles are parsed into words with white-space as separator, then removed of all characters not found in the English alphabet, though keeping the '-' character. All so called stop words are removed (such as "a", "the", etc.), and the words are stemmed so that similar words would be on the same form, and not be seen as two different words. (E.g., "argued", "argues", "arguing" are reduced to "argu".)
\subsection{Vocabulary}
The vocabulary is built up by unique stemmed words from the training set. By different pruning techniques the vocabulary is reduced in size and only the most informative elements are kept. For the feature selection the score is determined by the $\chi^2$ function. The vocabulary is then pruned by selecting a percentile of the best features.
\subsection{Data Types}
There are many different ways to represent a feature vector, and different classifiers might want it represented in different ways. We have chosen to investigate a couple of different types of representations of the vocabulary. The data types are
\begin{description}[noitemsep,labelindent=0.5cm]
\small
\item[Binary:]\ Does article contain the word or not.
\item[Count:]\ How many times does article contain the word.
\item[$L_2$-normalized:]\ The count array normalized with the $L_2$ norm. 
\item[Mapped value from 0 to 1:]\ $\frac{c_i}{\max(c)}$ where $c_i$ is the count of word $i$ in an article.
\end{description}

\subsection{Classifiers}
In the Scikit-learn package\footnote{\label{ftn:scikit}\url{http://scikit-learn.org/}} there are plenty of different classifiers, amongst them the four we want to investigate. The four classifiers we will be investigating are
\begin{itemize}[noitemsep,nolistsep]
\item Naïve Bayes: Bernoulli
\item Naïve Bayes: Multinomial
\item Random Forest 
\item Support Vector Machines
\end{itemize}

\subsubsection{\bn\ \nb} % (fold)
\label{ssub:bernoulli}
\input{sections/method_subsub/method_sub_ber.tex}
% subsubsection bernoulli (end)
\subsubsection{\mn\ \nb} % (fold)
\label{ssub:multinomial}
\input{sections/method_subsub/method_sub_mul.tex}
% subsubsection multinomial (end)
\subsubsection{\rf} % (fold)
\label{ssub:random_forest}
\input{sections/method_subsub/method_sub_rf.tex}
% subsubsection random_forest (end)
\subsubsection{\svm} % (fold)
\label{ssub:support_vector_machine}
\input{sections/method_subsub/method_sub_svm.tex}
% subsubsection support_vector_machine (end)
\subsubsection{\hy} % (fold)
\label{ssub:hybrid}
\input{sections/method_subsub/method_sub_hyb.tex}
% subsubsection hybrid (end)

\subsection{Investigation}
In order to compare the different classifiers and test their performance, the hit ratios will be investigated by varying the vocabulary size and the amount of articles in the training data for the different data types. Confusion matrices and results of how similarly the classifiers classify the articles might reveal strength and weaknesses of the classifiers as well as difficulties with the data.