%%%%%%%%%%%%%%%%%%%% DRAFT %%%%%%%%%%%%%%
\ifnum\printdraft>0
	\begin{itemize}
		\item Random forest is sensitive to uneven spread of data between topics. Probably needs same amount of each
		\item SVM handles increase in vocabulary size well. Should be resistant to high dimensionality.Feedback to theory.
		\item Why might sport and education be easy?
		\item Hybrid follows Multinomial since it's the default.
		\item Similarities between Tech / Science and Business / Education
		\item Low amount of data. Difficult to classify, even for a person.
		\item Why is random forest robust to data type?
		\item Naive bayes good for prediction, bad estimator
		\item All articles crawled at two points in time. Several articles may be about same thing, making it easier to predict with fewer articles in train set.
		\item Why do we only need like 50 articles to get a good classification? Maybe the thing with articles crawler at the same time.
	\end{itemize}
\else
\begin{center}
	\textbf{--- DRAFT PARTS ---}
\end{center}
\fi
%%%%%%%%%%%%%%%%%%%% END DRAFT %%%%%%%%%%
Interesting results and aspects of the report will be discussed further under this section, where we will give our analysis and input on \emph{why} we think the results turned out how they did. Later, under section \ref{sec:conc_future}, conclusions will be drawn, along with suggestions on what future project should focus upon.
\subsection{TEMP: Why is Random Forest robust to data type?} % (fold)
\label{sub:temp_why_is_random_forest_robust_to_data_type_}
The Random Forest classifier splits the data into two parts in each node depending on threshold values, so if the data is normalized or not, when building the tree, does not really matter for the classifier. What we would have expected would be to see a little bit difference in the binary data type, due to the fact that it discards how \emph{many} of each word the article contains.
% subsection temp_why_is_random_forest_robust_to_data_type_ (end)

\subsection{TEMP: Random Forest needs balanced data} % (fold)
\label{sub:temp_random_forest_needs_balanced_data}
One of the reason to why the Random Forest classifier tends to classify too many as sports is that Random Forest is sensitive to unbalanced training data, i.e., not having the same amount of training data for each class. In our case, we have more articles of the class sports, and less of politics and health. The classification in figure \ref{fig:confmat} follows this reasoning and shows that sports was classified 50 \% more than there are sports articles, while politics and health were classified 23 \% respectively 42 \% less than there are articles of that class.
% subsection temp_random_forest_need_balanced_data (end)

\subsection{TEMP: Hybrid follows Multinomial due to default} % (fold)
\label{sub:temp_hybrid_follows_multinomial_due_to_default}
In figures \ref{fig:hitratio} \& \ref{fig:confmat} we can see that the Hybrid classifier follows the trend of Multinomial, which is due to the fact that Multinomial is set as default in case of a tie in the voting.
% subsection temp_hybrid_follows_multinomial_due_to_default (end)

\subsection{TEMP: Hard to classify for person} % (fold)
\label{sub:temp_hard_to_classify_for_person}
Even a person might have difficulties to classify an article after reading it. A reason for this might be that the particular article does not contain enough information in order to distinguish the topic, which makes the classification difficult for a person as well. Imagine for example a football player, visiting a school to talk about politics.
\\\\
If we compare recognition of handwritten letters done by humans and computers, we might find that the hit ratio will be similar. We might have lots of data for recognition of handwritten letters, but when it comes to news articles, the news changes over time. For a human, a politics article might be distinguishable from a sports article due to the fact that we probably know more or less all words, but for our classifier, this will be a harder task if it was never exposed to the words. The classifier will need a lot of data over a long time to be able to recognize many types of words from different types of news.
\\\\
If one were to do a test out of a hundred articles from these eight topics, it would be interesting to see on average how the hit rate for a human would turn out.
% subsection temp_hard_to_classify_for_person (end)
